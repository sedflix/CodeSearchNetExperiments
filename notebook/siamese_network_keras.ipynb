{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../codesearchnet\")\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch_geometric.datasets import Planetoid\n",
    "# import torch_geometric.transforms as T\n",
    "# from torch_geometric.nn import GCNConv, GAE, VGAE\n",
    "# from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "\n",
    "import swifter\n",
    "import fasttext as ft\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import TensorboardTFLogger\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda, LSTM, Embedding, Bidirectional\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "\n",
    "from code_parser import *\n",
    "from data_reader import get_data_df\n",
    "from siamese_model_keras import *\n",
    "from keras_preprocessing_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dim_c, embeddings_dim_q = 256, 256\n",
    "max_len_code, max_len_query = 48, 28\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "exp_name = \"try\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load emebeddigs for for query and code\n",
    "query_ft = ft.load_model(\"../resources/python_processed/query_ft.bin\")\n",
    "code_ft = ft.load_model(\"../resources/python_processed/code_no_ast.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = get_generator(\"../resources/data/\", [\"python\"] , [\"train\"], max_len_query, max_len_code, query_ft, code_ft)\n",
    "valid_gen = get_generator(\"../resources/data/\", [\"python\"] , [\"valid\"], max_len_query, max_len_code, query_ft, code_ft)\n",
    "test_gen = get_generator(\"../resources/data/\", [\"python\"] , [\"test\"], max_len_query, max_len_code, query_ft, code_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_generator(train_gen,  \n",
    "                                    (tf.float32, tf.float32),  \n",
    "                                    (tf.TensorShape([max_len_query, embeddings_dim_q]),\n",
    "                                     tf.TensorShape([max_len_code, embeddings_dim_c])))\n",
    "\n",
    "valid_ds = tf.data.Dataset.from_generator(valid_gen,  \n",
    "                                    (tf.float32, tf.float32),  \n",
    "                                    (tf.TensorShape([max_len_query, embeddings_dim_q]),\n",
    "                                     tf.TensorShape([max_len_code, embeddings_dim_c])))\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(test_gen,  \n",
    "                                    (tf.float32, tf.float32),  \n",
    "                                    (tf.TensorShape([max_len_query, embeddings_dim_q]),\n",
    "                                     tf.TensorShape([max_len_code, embeddings_dim_c])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(batch_size).prefetch(batch_size*2)\n",
    "valid_ds = valid_ds.batch(batch_size).prefetch(batch_size*2)\n",
    "test_ds = test_ds.batch(batch_size).prefetch(batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_lstm(max_len_query, max_len_code, embeddings_dim_q, embeddings_dim_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liveloss = PlotLosses(outputs=[TensorboardTFLogger(\"./exp/tb/\", run_id=exp_name)])\n",
    "logs = {}\n",
    "best_val_loss = 100000.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # TRAINING\n",
    "    losses = []\n",
    "    mrrs = []\n",
    "    for x in train_ds:\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x)\n",
    "            loss_value = softmax_loss(None, logits)\n",
    "\n",
    "        mrr_value = mrr(None, logits)\n",
    "\n",
    "        # calculate gradient\n",
    "        gradients = tape.gradient(loss_value, model.trainable_variables)\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "        losses.append(loss_value)\n",
    "        mrrs.append(mrr_value)\n",
    "\n",
    "        print(f\"Epoch: {epoch}; Loss: {loss_value}; MRR: {mrr_value} <- Train\", end=\"\\r\")\n",
    "        \n",
    "    logs['loss'] = np.mean(losses)\n",
    "    logs['mrr'] = np.mean(mrrs)\n",
    "    \n",
    "    \n",
    "    # VALIDATION\n",
    "    losses = []\n",
    "    mrrs = []\n",
    "    for x in valid_ds:\n",
    "        \n",
    "        logits = model(x)\n",
    "        \n",
    "        loss_value = softmax_loss(None, logits)\n",
    "        mrr_value = mrr(None, logits)\n",
    "        \n",
    "        losses.append(loss_value)\n",
    "        mrrs.append(mrr_value)\n",
    "        \n",
    "        print(f\"Epoch: {epoch}; Loss: {loss_value}; MRR: {mrr_value} <- Test\", end=\"\\r\")\n",
    "        \n",
    "    logs['val_loss'] = np.mean(losses)\n",
    "    logs['val_mrr'] = np.mean(mrrs)\n",
    "    \n",
    "    if logs['val_loss'] < best_val_loss:\n",
    "        best_val_loss = logs['val_/loss']\n",
    "        model.save(f\"exp/{exp_name}.h5\")\n",
    "    \n",
    "    liveloss.update(logs)\n",
    "    liveloss.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f\"exp/{exp_name}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    losses = []\n",
    "    mrrs = []\n",
    "    for x in get_dataset(\"test\"):\n",
    "        \n",
    "        logits = model(x)\n",
    "        \n",
    "        loss_value = loss_(None, logits)\n",
    "        mrr_value = mrr(None, logits)\n",
    "        \n",
    "        losses.append(loss_value)\n",
    "        mrrs.append(mrr_value)\n",
    "        \n",
    "        print(f\"Epoch: test; Loss: {loss_value}; MRR: {mrr_value} <- Test\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(mrrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predit/Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f\"exp/{exp_name}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_encoder = tf.keras.models.Model(model.get_layer('input_1').input, model.get_layer('lstm').output)\n",
    "code_encoder = tf.keras.models.Model(model.get_layer('input_2').input, model.get_layer('lstm_1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature vector for both query and code\n",
    "querys = []\n",
    "codes = []\n",
    "\n",
    "for q,c in test_ds.take(1000):\n",
    "    querys.extend(query_encoder(q))\n",
    "    codes.extend(code_encoder(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an index for fast matching of vectors\n",
    "\n",
    "t = AnnoyIndex(256, 'angular')\n",
    "for i in range(len(codes)):\n",
    "    t.add_item(i, codes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the tree\n",
    "\n",
    "t.on_disk_build(\"exp/code_no_ast_embedding_screath_try.annoy_on_disk\")\n",
    "t.build(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the tree for later reference\n",
    "t.save('exp/code_no_ast_embedding_screath_try.annoyme')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = t.get_nns_by_vector(codes[2155], n=2, include_distances=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0 \n",
    "for i in range(len(querys)):\n",
    "    result = t.get_nns_by_vector(querys[i], n=10, include_distances=False)\n",
    "    if i in result:\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct/len(querys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## snippet for loading a tree\n",
    "from annoy import AnnoyIndex\n",
    "t = AnnoyIndex(256, 'angular')\n",
    "t.load('exp/code_no_ast_embedding_screath_try.annoyme')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../resources/data/python_dedupe_definitions_v2.pkl\", \"rb\") as f:\n",
    "    import pickle \n",
    "    definations = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
